{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import tqdm\n",
    "import json\n",
    "import bs4\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "no_of_rooms = {'2 ROOM': 2, '3 ROOM': 3, '4 ROOM': 4, '5 ROOM': 5, 'EXECUTIVE': 4, 'MULTI-GENERATION': 5, '1 ROOM': 1}\n",
    "\n",
    "def convert_to_years(x):\n",
    "    if len(x) == 1:\n",
    "        return int(x[0])\n",
    "    else:\n",
    "        return float(x[0]) + float(x[1])/12\n",
    "\n",
    "df2023 = pd.read_csv(\"ResaleflatpricesbasedonregistrationdatefromJan2017onwards.csv\")\n",
    "df2023 = df2023[df2023.month.apply(lambda x: x.split(\"-\")[0] == \"2023\")]\n",
    "df2023.month = df2023.month.apply(lambda x: months[int(x.split(\"-\")[1])-1])\n",
    "df2023.remaining_lease = df2023.remaining_lease.str.findall(\"\\d{2}\").apply(convert_to_years)\n",
    "df2023.remaining_lease = df2023.lease_commence_date + 99 - 2023\n",
    "df2023[\"avg_storey\"] = df2023.storey_range.str.findall(\"\\d{2}\").apply(lambda x: (int(x[0]) + int(x[1]))/2)\n",
    "df2023[\"no_of_rooms\"] = df2023.flat_type.apply(lambda x: no_of_rooms[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agepopdf = pd.read_excel(\"PopData.xls\", header = 5, sheet_name = \"AgeGroupPop\").iloc[:, 1:].dropna(subset = [\"Subzone\"])\n",
    "agepopdf[\"Planning Area\"] = agepopdf[\"Planning Area\"].ffill()\n",
    "agepopdf = agepopdf[~(agepopdf.Subzone == \"Total\") & ~(agepopdf.Subzone == \"Subzone\")]\n",
    "agepopdf = agepopdf.drop(\"Total\", axis = 1)\n",
    "agepopdf.columns = [\"area\", \"subarea\", \"2yrPop\", \"7yrPop\", \"12yrPop\", \"17yrPop\", \"22yrPop\", \"27yrPop\", \"32yrPop\", \"37yrPop\", \"42yrPop\", \"47yrPop\", \"52yrPop\", \"57yrPop\", \"62yrPop\", \"67yrPop\", \"72yrPop\", \"77yrPop\", \"82yrPop\", \"90yrPop\"]\n",
    "ethnicpopdf = pd.read_excel(\"PopData.xls\", header = 5, sheet_name = \"EthnicityPop\").iloc[:, 1:].dropna(subset = [\"Subzone\"])\n",
    "ethnicpopdf[\"Planning Area\"] = ethnicpopdf[\"Planning Area\"].ffill()\n",
    "ethnicpopdf = ethnicpopdf[~(ethnicpopdf.Subzone == \"Total\") & ~(ethnicpopdf.Subzone == \"Subzone\")]\n",
    "ethnicpopdf = ethnicpopdf.drop(\"Total\", axis = 1)\n",
    "ethnicpopdf = ethnicpopdf[[\"Planning Area\", \"Subzone\", \"Chinese\", \"Malays\", \"Indians\", \"Others\"]]\n",
    "ethnicpopdf.columns = [\"area\", \"subarea\", \"chinesePop\", \"malayPop\", \"indianPop\", \"otherPop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inddf = pd.read_excel(\"IncomeData.xls\", sheet_name = \"IndByArea\")\n",
    "occdf = pd.read_excel(\"IncomeData.xls\", sheet_name = \"OccByArea\")\n",
    "incomedf = pd.read_excel(\"IncomeData.xls\", sheet_name = \"MonthlyIncomeByArea\")\n",
    "transportdf = pd.read_excel(\"IncomeData.xls\", sheet_name = \"TransportByArea\")\n",
    "traveltimedf = pd.read_excel(\"IncomeData.xls\", sheet_name = \"AvgTravelTimeByArea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch_df = pd.read_csv(r\"2021PrimarySchools.csv\")\n",
    "trans_df = pd.read_csv(r\"MrtLrt.csv\")\n",
    "beaches = [\"East Coast Park\", \"Sembawang Park\", \"West Coast Park\", \"Pasir Ris Park\", \"Changi Beach Park\", \"Punggol Beach\", \"Palawan Beach\", \"Siloso Beach\", \"Tanjong Beach\", \"Tonjong Rimau Beach\", \"Ketam Beach\", \"Ketam Beach\", \"Lazarus Island\", \"Saint John's Island\", \"Coney Island\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcoordinates(address, token_header):\n",
    "    req = requests.get('https://www.onemap.gov.sg/api/common/elastic/search?searchVal='+address+'&returnGeom=Y&getAddrDetails=Y&pageNum=1', headers = token_header)\n",
    "    if req.status_code == 200:\n",
    "        resultsdict = eval(req.text)\n",
    "        if len(resultsdict['results'])>0:\n",
    "            return resultsdict['results'][0]['LATITUDE'], resultsdict['results'][0]['LONGITUDE']\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        print(req.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_header = {\"Authorization\": \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiI1OWNjYWMwYzhlZjc0OWUxNzQ1NGI0OGE3MDI5NWQ1NSIsImlzcyI6Imh0dHA6Ly9pbnRlcm5hbC1hbGItb20tcHJkZXppdC1pdC0xMjIzNjk4OTkyLmFwLXNvdXRoZWFzdC0xLmVsYi5hbWF6b25hd3MuY29tL2FwaS92Mi91c2VyL3Bhc3N3b3JkIiwiaWF0IjoxNzA5NTI3MTk4LCJleHAiOjE3MDk3ODYzOTgsIm5iZiI6MTcwOTUyNzE5OCwianRpIjoiSFJqMGZEVGpDQTdKUXRRcSIsInVzZXJfaWQiOjI3NzMsImZvcmV2ZXIiOmZhbHNlfQ.vVR5JF1DQkUVKjuRpQAH3qSsRKR_1gawO-a5AfMLE4M\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "beach_df = pd.DataFrame({\"beachName\": beaches, \"beachCoord\": [getcoordinates(beach_name, token_header) for beach_name in beaches]})\n",
    "beach_df = beach_df.join(pd.DataFrame(beach_df.beachCoord.to_list()).rename({0: \"lat\", 1: \"long\"}, axis = 1)).drop(\"beachCoord\", axis = 1)\n",
    "beach_df = beach_df.dropna().reset_index(drop = True)\n",
    "beach_df.to_csv(\"beaches.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169/169 [01:08<00:00,  2.47it/s]\n"
     ]
    }
   ],
   "source": [
    "shopping_malls = requests.get(\"https://en.wikipedia.org/wiki/List_of_shopping_malls_in_Singapore\")\n",
    "shopping_malls = bs4.BeautifulSoup(shopping_malls.text)\n",
    "shopping_malls = shopping_malls.find_all(attrs = \"div-col\")\n",
    "shopping_malls = [re.sub(\"\\[\\d+\\]\", \"\", mall_name.text) for region in shopping_malls for mall_name in region.find_all(\"li\")]\n",
    "\n",
    "mall_df = pd.DataFrame({\"mallName\": shopping_malls, \"mallCoord\": [getcoordinates(mall_name, token_header) for mall_name in tqdm.tqdm(shopping_malls)]})\n",
    "mall_df = mall_df.join(pd.DataFrame(mall_df.mallCoord.to_list()).rename({0: \"lat\", 1: \"long\"}, axis = 1)).drop(\"mallCoord\", axis = 1)\n",
    "mall_df = mall_df.dropna()\n",
    "mall_df.to_csv(\"malls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresslist = (df2023.street_name + \" \" + df2023.block).drop_duplicates()\n",
    "\n",
    "hdbCoordinates = [getcoordinates(address, token_header) for address in tqdm.tqdm(addresslist)]\n",
    "hdbCoordinates = pd.DataFrame(hdbCoordinates)\n",
    "hdbCoordinates.columns = [\"lat\", \"long\"]\n",
    "hdbCoordinates[\"address\"] = addresslist.values\n",
    "\n",
    "missing_address = hdbCoordinates[hdbCoordinates.lat.isna()].address\n",
    "missing_coord = [getcoordinates(address, token_header) for address in tqdm.tqdm(missing_address)]\n",
    "hdbCoordinates.loc[hdbCoordinates.address.isin(missing_address.values), [\"lat\", \"long\"]] = missing_coord\n",
    "# hdbCoordinates.to_csv(\"hdbCoord.csv\")\n",
    "# hdbCoordinates = pd.read_csv(\"hdbCoord.csv\").iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTravelDistTime(loc1, loc2, type = \"pt\", auth = token_header):\n",
    "    req =  f\"https://www.onemap.gov.sg/api/public/routingsvc/route?start={loc1[0]}%2C{loc1[1]}&end={loc2[0]}%2C{loc2[1]}&routeType={type}&date=08-13-2023&time=12%3A00%3A00&mode=TRANSIT&numItineraries=1\"\n",
    "    req = requests.get(req, headers = auth)\n",
    "    if req.status_code == 200:\n",
    "        resultsdict = json.loads(req.text)\n",
    "        if type == \"pt\":\n",
    "            itineraries = resultsdict[\"plan\"][\"itineraries\"]\n",
    "            if len(itineraries) > 0:\n",
    "                itinDist = sum([x[\"distance\"] for x in itineraries[0][\"legs\"]])/1000\n",
    "                itinDura = itineraries[0][\"duration\"]/60\n",
    "        elif (type in [\"walk\", \"drive\"]) and (resultsdict[\"status\"] == 0):\n",
    "            itinDist = resultsdict[\"route_summary\"][\"total_distance\"]/1000\n",
    "            itinDura = resultsdict[\"route_summary\"][\"total_time\"]/60\n",
    "        else:\n",
    "            itinDist = None\n",
    "            itinDura = None\n",
    "            \n",
    "        return (itinDist, itinDura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "beach_df.columns = [\"name\", \"lat\", \"long\"]\n",
    "trans_df.columns = [\"name\", \"type\", \"lat\", \"long\"]\n",
    "mall_df.columns = [\"name\", \"lat\", \"long\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closest school (drive), beach (drive), mall (drive) and public transport (walk)\n",
    "\n",
    "def findClosestEntity(focus, entity_df, dist_type = \"drive\", auth_token = token_header, radius = 10):\n",
    "    entityDistTime = entity_df[[\"lat\", \"long\"]].apply(lambda x: getTravelDistTime(focus, x.values, type = dist_type, auth = auth_token), axis = 1)\n",
    "    entityDistTime = pd.DataFrame(list(entityDistTime))\n",
    "    minDist = entityDistTime.min().values[0]\n",
    "    minTime = entityDistTime[entityDistTime[0] == minDist][1]\n",
    "    closestEntity = entity_df[entityDistTime[0] == minDist][\"name\"].values[0]\n",
    "    no_within_radius = sum(entityDistTime[0] <= radius)\n",
    "    \n",
    "    return (closestEntity, minDist, minTime, no_within_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/7954 [01:26<20:48:52,  9.43s/it]"
     ]
    }
   ],
   "source": [
    "tqdm.tqdm.pandas()\n",
    "\n",
    "closestBeaches = hdbCoordinates[[\"lat\", \"long\"]].progress_apply(lambda x: findClosestEntity(x.values, beach_df), axis = 1)\n",
    "closestMalls = hdbCoordinates[[\"lat\", \"long\"]].progress_apply(lambda x: findClosestEntity(x.values, mall_df), axis = 1)\n",
    "closestPrimarySch = hdbCoordinates[[\"lat\", \"long\"]].progress_apply(lambda x: findClosestEntity(x.values, sch_df), axis = 1)\n",
    "closestMRTStation = hdbCoordinates[[\"lat\", \"long\"]].progress_apply(lambda x: findClosestEntity(x.values, trans_df, dist_type = \"walk\"), axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
